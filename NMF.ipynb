{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dfa9f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d22c5cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d376ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('ratings.csv').drop(['Unnamed: 0'], axis=1)\n",
    "providers = pd.read_csv('providers.csv').drop(['Unnamed: 0'], axis=1)\n",
    "reg = ratings['Registration number'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a68d159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttsplit(examples, labels, test_size=0.1, verbose=0):\n",
    "    \"\"\"\n",
    "    Split examples and labels into train and test sets.\n",
    "\n",
    "    Args:\n",
    "        examples (numpy array): Input examples.\n",
    "        labels (numpy array): Corresponding labels.\n",
    "        test_size (float, optional): The proportion of the data to include in the test split. Defaults to 0.1.\n",
    "        verbose (int, optional): Verbosity mode. If 1, prints information about the split. Defaults to 0.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Tuple containing the train and test sets for examples and labels.\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Train/Test split\")\n",
    "        print(f\"{100 - test_size * 100}% of training data\")\n",
    "        print(f\"{test_size * 100}% of testing data\")\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    train_examples, test_examples, train_labels, test_labels = train_test_split(\n",
    "        examples, labels, test_size=test_size, random_state=0, shuffle=True\n",
    "    )\n",
    "\n",
    "    # Transform train and test examples to their corresponding one-hot representations\n",
    "    train_users = train_examples[:, 0]\n",
    "    test_users = test_examples[:, 0]\n",
    "\n",
    "    train_items = train_examples[:, 1]\n",
    "    test_items = test_examples[:, 1]\n",
    "\n",
    "    # Final training and test set\n",
    "    x_train = np.array(list(zip(train_users, train_items)))\n",
    "    x_test = np.array(list(zip(test_users, test_items)))\n",
    "\n",
    "    y_train = train_labels\n",
    "    y_test = test_labels\n",
    "\n",
    "    if verbose:\n",
    "        print()\n",
    "        print('Number of training examples:', x_train.shape)\n",
    "        print('Number of training labels:', y_train.shape)\n",
    "        print('Number of test examples:', x_test.shape)\n",
    "        print('Number of test labels:', y_test.shape)\n",
    "\n",
    "    return (x_train, x_test), (y_train, y_test)\n",
    "\n",
    "\n",
    "\n",
    "def calculate_mean_ratings(dataframe):\n",
    "    \"\"\"\n",
    "    Calculate the mean ratings grouped by User_id.\n",
    "    \n",
    "    Args:\n",
    "        dataframe (DataFrame): Input data.\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: A DataFrame containing the mean ratings for each User_id.\n",
    "    \"\"\"\n",
    "    mean_ratings = dataframe.groupby(by=\"User_id\", as_index=False)[\"rating\"].mean()\n",
    "    return mean_ratings\n",
    "\n",
    "\n",
    "def normalize_ratings(dataframe, norm_column=\"norm_rating\"):\n",
    "    \"\"\"\n",
    "    Normalize the user ratings relative to the overall mean.\n",
    "    \n",
    "    Args:\n",
    "        dataframe (DataFrame): Input data.\n",
    "        norm_column (str): Name of the column for normalized ratings.\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: A DataFrame with the normalized ratings.\n",
    "    \"\"\"\n",
    "    mean_ratings = calculate_mean_ratings(dataframe=dataframe)\n",
    "    normalized_data = pd.merge(dataframe, mean_ratings, suffixes=(\"\", \"_mean\"), on=\"User_id\")\n",
    "    normalized_data[f\"{norm_column}\"] = normalized_data[\"rating\"] - normalized_data[\"rating_mean\"]\n",
    "\n",
    "    return normalized_data\n",
    "\n",
    "\n",
    "def create_rating_matrix(dataframe, column):\n",
    "    \"\"\"\n",
    "    Generate a rating matrix from the dataframe.\n",
    "    \n",
    "    Args:\n",
    "        dataframe (DataFrame): Input data.\n",
    "        column (str): Name of the column to use for the matrix.\n",
    "        \n",
    "    Returns:\n",
    "        csr_matrix: A sparse rating matrix.\n",
    "    \"\"\"\n",
    "    crosstab = pd.crosstab(\n",
    "        dataframe[\"User_id\"], dataframe[\"Registration number\"], dataframe[f\"{column}\"], aggfunc=sum\n",
    "    ).fillna(0).values()\n",
    "    rating_matrix = csr_matrix(crosstab)\n",
    "    return rating_matrix\n",
    "\n",
    "\n",
    "def scale_ratings(dataframe, scaled_column=\"scaled_rating\"):\n",
    "    \"\"\"\n",
    "    Scale the ratings between 0 and 1.\n",
    "    \n",
    "    Args:\n",
    "        dataframe (DataFrame): Input data.\n",
    "        scaled_column (str): Name of the column for scaled ratings.\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: A DataFrame with the scaled ratings.\n",
    "    \"\"\"\n",
    "    dataframe[f\"{scaled_column}\"] = dataframe.rating / 5.0\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def get_examples_and_labels(dataframe, labels_column=\"rating\"):\n",
    "    \"\"\"\n",
    "    Get the input examples and corresponding labels from the dataframe.\n",
    "    \n",
    "    Args:\n",
    "        dataframe (DataFrame): Input data.\n",
    "        labels_column (str): Name of the column containing the labels.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: A tuple containing the examples and labels.\n",
    "    \"\"\"\n",
    "    examples = dataframe[[\"User_id\", \"Registration number\"]].values\n",
    "    labels = dataframe[f\"{labels_column}\"].values\n",
    "    return examples, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4f7fda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_encoder(ratings):\n",
    "    \"\"\"\n",
    "    Encode User_id and Registration number for easier processing.\n",
    "    \n",
    "    Args:\n",
    "        ratings (DataFrame): Input ratings data.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: A tuple containing the encoded ratings, user encoder, and item encoder.\n",
    "    \"\"\"\n",
    "    # Get unique users and items\n",
    "    users = sorted(ratings['User_id'].unique())\n",
    "    items = sorted(ratings['Registration number'].unique())\n",
    "\n",
    "    # Encoder for users and items\n",
    "    user_encoder = LabelEncoder()\n",
    "    item_encoder = LabelEncoder()\n",
    "\n",
    "    # Fit encoders to users and items\n",
    "    user_encoder.fit(users)\n",
    "    item_encoder.fit(items)\n",
    "\n",
    "    # Rewrite User_id and Registration number with encoded values\n",
    "    ratings['User_id'] = user_encoder.transform(ratings['User_id'].tolist())\n",
    "    ratings['Registration number'] = item_encoder.transform(ratings['Registration number'].tolist())\n",
    "\n",
    "    return ratings, user_encoder, item_encoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d81b6c",
   "metadata": {},
   "source": [
    "## Non-negative Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e2489cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMF:\n",
    "    def __init__(self, ratings, m, n, uencoder, iencoder, K=10, lambda_P=0.01, lambda_Q=0.01):\n",
    "        \"\"\"\n",
    "        Initialize the NMF model with the given parameters.\n",
    "        \n",
    "        Args:\n",
    "            ratings (DataFrame): Input ratings data.\n",
    "            m (int): Number of users.\n",
    "            n (int): Number of items.\n",
    "            uencoder (LabelEncoder): User encoder.\n",
    "            iencoder (LabelEncoder): Item encoder.\n",
    "            K (int): Number of latent factors.\n",
    "            lambda_P (float): Regularization parameter for P matrix.\n",
    "            lambda_Q (float): Regularization parameter for Q matrix.\n",
    "        \"\"\"\n",
    "        np.random.seed(32)\n",
    "        \n",
    "        # Initialize P and Q matrices with random values\n",
    "        self.ratings = ratings\n",
    "        self.np_ratings = ratings.to_numpy()\n",
    "        self.K = K\n",
    "        self.P = np.random.rand(m, K)\n",
    "        self.Q = np.random.rand(n, K)\n",
    "        \n",
    "        # Set hyperparameters\n",
    "        self.lambda_P = lambda_P\n",
    "        self.lambda_Q = lambda_Q\n",
    "\n",
    "        # Store user and item encoders\n",
    "        self.uencoder = uencoder\n",
    "        self.iencoder = iencoder\n",
    "        \n",
    "        # Dictionary to store training history\n",
    "        self.history = {\n",
    "            \"epochs\": [],\n",
    "            \"loss\": [],\n",
    "            \"val_loss\": [],\n",
    "        }\n",
    "\n",
    "    def print_training_parameters(self):\n",
    "        \"\"\"\n",
    "        Print the training parameters.\n",
    "        \"\"\"\n",
    "        print(\"Training NMF ...\")\n",
    "        print(f\"k={self.K}\")\n",
    "        \n",
    "    def mae(self, x_train, y_train):\n",
    "        \"\"\"\n",
    "        Calculate the mean absolute error (MAE) on the training set.\n",
    "        \n",
    "        Args:\n",
    "            x_train (array-like): Training examples.\n",
    "            y_train (array-like): Training labels.\n",
    "            \n",
    "        Returns:\n",
    "            float: The MAE value.\n",
    "        \"\"\"\n",
    "        M = x_train.shape[0]\n",
    "        error = 0\n",
    "        for pair, r in zip(x_train, y_train):\n",
    "            u, i = pair\n",
    "            error += abs(r - np.dot(self.P[u], self.Q[i]))\n",
    "        return error / M\n",
    "    \n",
    "    def update_rule(self, u, i, error):\n",
    "        \"\"\"\n",
    "        Update the P and Q matrices based on the NMF update rule.\n",
    "        \n",
    "        Args:\n",
    "            u (int): User index.\n",
    "            i (int): Item index.\n",
    "            error (float): Prediction error.\n",
    "        \"\"\"\n",
    "        # Retrieve relevant indices and values from ratings data\n",
    "        I = self.np_ratings[self.np_ratings[:, 0] == u][:, [1, 2]]\n",
    "        U = self.np_ratings[self.np_ratings[:, 1] == i][:, [0, 2]]    \n",
    "        \n",
    "        # Calculate the numerator and denominator for updating P\n",
    "        l = I[:, 0].astype(int)\n",
    "        num = self.P[u] * np.dot(self.Q[l].T, I[:, 1])\n",
    "        dem = np.dot(self.Q[l].T, np.dot(self.P[u], self.Q[l].T)) + self.lambda_P * len(I) * self.P[u]\n",
    "        self.P[u] = num / dem\n",
    "        \n",
    "        # Calculate the numerator and denominator for updating Q\n",
    "        m = U[:, 0].astype(int)\n",
    "        num = self.Q[i] * np.dot(self.P[m].T, U[:, 1])\n",
    "        dem = np.dot(self.P[m].T, np.dot(self.P[m], self.Q[i].T)) + self.lambda_Q * len(U) * self.Q[i]\n",
    "        self.Q[i] = num / dem\n",
    "    \n",
    "    @staticmethod\n",
    "    def print_training_progress(epoch, epochs, error, val_error, steps=5):\n",
    "        \"\"\"\n",
    "        Print the training progress at certain steps.\n",
    "        \n",
    "        Args:\n",
    "            epoch (int): Current epoch number.\n",
    "            epochs (int): Total number of epochs.\n",
    "            error (float): Training error.\n",
    "            val_error (float): Validation error.\n",
    "            steps (int): Number of steps to print progress.\n",
    "        \"\"\"\n",
    "        if epoch == 1 or epoch % steps == 0:\n",
    "            print(f\"epoch {epoch}/{epochs} - loss: {round(error, 3)} - val_loss: {round(val_error, 3)}\")\n",
    "                   \n",
    "    def fit(self, x_train, y_train, validation_data, epochs=10):\n",
    "        \"\"\"\n",
    "        Train the NMF model using the given training data.\n",
    "        \n",
    "        Args:\n",
    "            x_train (array-like): Training examples.\n",
    "            y_train (array-like): Training labels.\n",
    "            validation_data (tuple): Tuple containing validation examples and labels.\n",
    "            epochs (int): Number of training epochs.\n",
    "            \n",
    "        Returns:\n",
    "            dict: Dictionary containing training history.\n",
    "        \"\"\"\n",
    "        self.print_training_parameters()\n",
    "        x_test, y_test = validation_data\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            for pair, r in zip(x_train, y_train):\n",
    "                u, i = pair\n",
    "                r_hat = np.dot(self.P[u], self.Q[i])\n",
    "                e = abs(r - r_hat)\n",
    "                self.update_rule(u, i, e)                \n",
    "            # Training and validation evaluation\n",
    "            error = self.mae(x_train, y_train)\n",
    "            val_error = self.mae(x_test, y_test)\n",
    "            self.update_history(epoch, error, val_error)\n",
    "            self.print_training_progress(epoch, epochs, error, val_error, steps=1)\n",
    "        \n",
    "        return self.history\n",
    "    \n",
    "    def update_history(self, epoch, error, val_error):\n",
    "        \"\"\"\n",
    "        Update the training history with the current epoch and error values.\n",
    "        \n",
    "        Args:\n",
    "            epoch (int): Current epoch number.\n",
    "            error (float): Training error.\n",
    "            val_error (float): Validation error.\n",
    "        \"\"\"\n",
    "        self.history['epochs'].append(epoch)\n",
    "        self.history['loss'].append(error)\n",
    "        self.history['val_loss'].append(val_error)\n",
    "    \n",
    "    def evaluate(self, x_test, y_test):        \n",
    "        \"\"\"\n",
    "        Evaluate the NMF model on the given test data.\n",
    "        \n",
    "        Args:\n",
    "            x_test (array-like): Test examples.\n",
    "            y_test (array-like): Test labels.\n",
    "            \n",
    "        Returns:\n",
    "            float: The mean absolute error (MAE) on the test data.\n",
    "        \"\"\"\n",
    "        error = self.mae(x_test, y_test)\n",
    "        print(f\"validation error: {round(error, 3)}\")\n",
    "        print('MAE:', error)        \n",
    "        return error\n",
    "      \n",
    "    def predict(self, userid, itemid):\n",
    "        \"\"\"\n",
    "        Predict the rating for a given user and item.\n",
    "        \n",
    "        Args:\n",
    "            userid (int): User ID.\n",
    "            itemid (int): Item ID.\n",
    "            \n",
    "        Returns:\n",
    "            float: The predicted rating.\n",
    "        \"\"\"\n",
    "        u = self.uencoder.transform([userid])[0]\n",
    "        i = self.iencoder.transform([itemid])[0]\n",
    "        \n",
    "        # Calculate the rating prediction\n",
    "        r = np.dot(self.P[u], self.Q[i])\n",
    "        return r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ae40be",
   "metadata": {},
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95286829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training NMF ...\n",
      "k=10\n",
      "epoch 1/15 - loss: 0.635 - val_loss: 0.854\n",
      "epoch 2/15 - loss: nan - val_loss: 0.802\n",
      "epoch 3/15 - loss: nan - val_loss: 0.79\n",
      "epoch 4/15 - loss: nan - val_loss: 0.782\n",
      "epoch 5/15 - loss: nan - val_loss: 0.775\n",
      "epoch 6/15 - loss: nan - val_loss: 0.768\n",
      "epoch 7/15 - loss: nan - val_loss: 0.763\n",
      "epoch 8/15 - loss: nan - val_loss: 0.759\n",
      "epoch 9/15 - loss: nan - val_loss: 0.755\n",
      "epoch 10/15 - loss: nan - val_loss: 0.752\n",
      "epoch 11/15 - loss: nan - val_loss: 0.749\n",
      "epoch 12/15 - loss: nan - val_loss: 0.746\n",
      "epoch 13/15 - loss: nan - val_loss: 0.744\n",
      "epoch 14/15 - loss: nan - val_loss: 0.741\n",
      "epoch 15/15 - loss: nan - val_loss: 0.739\n"
     ]
    }
   ],
   "source": [
    "## initial rating\n",
    "m = ratings['User_id'].nunique()   # всего пользователей\n",
    "n = ratings['Registration number'].nunique()   # всего элементов\n",
    "\n",
    "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
    "\n",
    "# получение данных в подготовленном виде\n",
    "raw_examples, raw_labels = get_examples_and_labels(ratings)\n",
    "\n",
    "# train test split\n",
    "(x_train, x_test), (y_train, y_test) = ttsplit(examples=raw_examples, labels=raw_labels)\n",
    "\n",
    "m = ratings['User_id'].nunique()  \n",
    "n = ratings['Registration number'].nunique() \n",
    "\n",
    "# обучаем\n",
    "nmf = NMF(ratings, m, n, uencoder, iencoder, K=10, lambda_P=0.6, lambda_Q=0.6)\n",
    "history = nmf.fit(x_train, y_train, epochs=15, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ec78b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation error: 0.739\n",
      "MAE: 0.7391805920159994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7391805920159994"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc163b5",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d9c44e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user2userPredictions(userid, pred_path, reg):\n",
    "    \"\"\"\n",
    "    Generate predictions for each user and save them to the file predictionNMF.csv\n",
    "    \n",
    "    Args:\n",
    "        userid (int): User ID.\n",
    "        pred_path (str): Path to save the predictions.\n",
    "        reg (dict): Dictionary mapping registration numbers to some values.\n",
    "    \"\"\"\n",
    "    # Find registered numbers\n",
    "    reg_num = set(ratings['Registration number'].tolist())\n",
    "    user = set(ratings[ratings['User_id'] == userid]['Registration number'].tolist())\n",
    "    diff = list(reg_num - user)\n",
    "    \n",
    "    try:\n",
    "        # Iterate over selected users for prediction\n",
    "        for itemid in diff:\n",
    "            # Make prediction for the user on items\n",
    "            r_hat = nmf.predict(userid, itemid)\n",
    "            # Save the prediction\n",
    "            with open(pred_path, 'a+') as file:\n",
    "                line = '{},{},{}\\n'.format(userid, reg[itemid], r_hat)\n",
    "                file.write(line)\n",
    "    except IndexError:\n",
    "        pass\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def user2userNMF(reg):\n",
    "    \"\"\"\n",
    "    Perform predictions for all users, including users with only 1 rating.\n",
    "    \n",
    "    Args:\n",
    "        reg (dict): Dictionary mapping registration numbers to some values.\n",
    "    \"\"\"\n",
    "    # List of all users\n",
    "    users = ratings['User_id'].unique()\n",
    "    \n",
    "    def _progress(count):\n",
    "        sys.stdout.write('\\rRating predictions. Progress status: %.1f%%' % (float(count/len(users))*100.0))\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    saved_predictions = 'predictionsNMF.csv'    \n",
    "    if os.path.exists(saved_predictions):\n",
    "        os.remove(saved_predictions)\n",
    "    \n",
    "    for count, userid in enumerate(users):\n",
    "        # Make prediction\n",
    "        user2userPredictions(userid, saved_predictions, reg)\n",
    "        _progress(count)\n",
    "\n",
    "def user2userRecommendation(userid, N):\n",
    "    \"\"\"\n",
    "    Generate predictions for a specific user.\n",
    "    \n",
    "    Args:\n",
    "        userid (int): User ID.\n",
    "        N (int): Number of recommendations to return.\n",
    "    \n",
    "    Returns:\n",
    "        pandas DataFrame: Top N recommendations for the user.\n",
    "    \"\"\"\n",
    "    \n",
    "    saved_predictions = 'predictionsNMF.csv'\n",
    "    \n",
    "    predictions = pd.read_csv(saved_predictions, sep=',', names=['User_id', 'Registration number', 'predicted_rating'])\n",
    "    predictions = predictions[predictions['User_id'] == userid]\n",
    "    top_n_list = predictions.sort_values(by=['predicted_rating'], ascending=False)[:N]\n",
    "    \n",
    "    top_n_list = pd.merge(top_n_list, providers, on='Registration number', how='inner')\n",
    "    \n",
    "    return top_n_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09db565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.userid = uencoder.inverse_transform(ratings['User_id'].to_list())\n",
    "ratings.itemid = iencoder.inverse_transform(ratings['Registration number'].to_list())\n",
    "reg_num = set(ratings['Registration number'].tolist())\n",
    "user = set(ratings[ratings['User_id'] == 0]['Registration number'].tolist())\n",
    "diff = list(reg_num - user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e776fafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4912798633002122"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NMF.predict(nmf, userid=0, itemid=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b58e2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating predictions. Progress status: 98.0%"
     ]
    }
   ],
   "source": [
    "user2userNMF(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56cf4e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['СИБИРСКИЙ ДИСТРИБЬЮТОР, ООО',\n",
       " 'ЭКО-ПИК, ООО',\n",
       " 'АМУР-ХЭ, ООО',\n",
       " 'ПИРОГОВСКОЕ, ООО МК',\n",
       " 'АПЭК, ООО']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = user2userRecommendation(0, 5).drop(['Registration number', 'Предмет поставки', 'Важная информация'], axis=1)\n",
    "# k[k['Сводный индикатор'] == 'Низкий риск']['Наименование'].tolist()\n",
    "k['Наименование'].tolist()\n",
    "# k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbf9354",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
